# arithmetic-calculator
### by Carl Cassar
This repo documents the process of writing an arithmetic calculator. The calculator program is written in Python and reads a string of text containing an arithmetic operation, analyses the string, evaluates the expression, and returns the computed answer. To do this, the program is split into three main parts: a lexical analyser which converts a single string into a list of tokens; a parser which uses the tokens emitted by the lexer to generate an intermediate representation of the expression by converting infix notation to postfix notation using Dijkstra’s shunting-yard algorithm; and an evaluator which uses the parser’s postfix output to compute the answer of the expression by performing the relevant arithmetic operations in a specific order.

### Architecture
As explained, there are 3 main components to the program: the lexer is written in the ‘calcLexer.py’ file; the parser is written in the ‘calcParser.py’ file; and the evaluator is written in the ‘calcEval.py’ file. Each file is called a module. Apart from computing the final answer, the evaluator module also handles user interaction, i.e. when the user runs the evaluator module, the terminal prompts the user to input an arithmetic expression. Once an expression is entered, the evaluator module imports the relevant functions from the other modules, executes them, checks for the validity of the expression, computes the answer (if the expression is valid), and displays it to the user in the terminal. The flow of data between the user and different modules is shown in the figure below.

![architecture](https://github.com/utlond/arithmetic-calculator/blob/main/architecture.png)

### The Lexical Analyser
The code for the lexical analyser is written in a Python module called ‘calcLexer’. The lexical analyser, or the lexer, takes a single string input and generates a list of sub-strings. Each sub-string is called a token and contains one or more characters present in the original string. Each token is a parenthesis (open or close), a number (positive or negative integers/floats) or an operator (+, -, *, /, ^).

The lexer removes any leading and trailing whitespace from the input string, and then scans each part of the string to check for parentheses, numbers and operators.

In total, there are 4 functions inside the ‘calcLexer’ file. These are:

- **isStrA_Num** which checks whether a group of ASCII characters can be converted to a single integer or float;
- **parSpacesIdx** which analyses the original arithmetic expression and returns the positions of parentheses and whitespace inside the string;
- **operIdx** which identifies the positions of the operators inside the string, and returns a list containing the positions of parentheses, spaces and operators; and
- **genTokens** which produces 2 lists: a list of tokens, and a list of token labels.

#### The ***isStrA_Num*** Function

This function takes one string as an input and checks if it is a single number. It does this by first eliminating any leading and trailing whitespace. It then follows a set of rules to decide whether the input is a single number:

Rule 1: Any characters which are not numeric, + or -, or ., cannot be part of a number.

Rule 2: A + or – can be part of a number only if it occurs once, at the start of the string.

Rule 3: A number cannot contain any whitespace between any of its characters.

Rule 4: A decimal point can only occur once, anywhere, except at the end of the string.

If the string does not break any of these rules, then the function returns a tuple containing a boolean value of ‘True’ and the original string without any leading or trailing whitespace. Otherwise, a boolean value of ‘False’ is returned.

#### The ***genTokens*** Function

This function is the main code for the lexer module. It takes 3 inputs from the **operIdx** function in the following order: a list of indexes indicating the positions of parentheses, spaces and operators in the string; the string itself (without any leading and trailing whitespace); and a list containing all indexes of the string.

### The Parser

The code for the parser is written in a Python module called ‘calcParser’. The main task of the parser is to convert the arithmetic expression from infix to postfix. The infix format is the common way in which people write mathematical expressions, i.e. operands are always separated by operators. This conversion is carried out because it is easier for computers to evaluate a postfix expression. Before converting the infix expression to postfix format, the parser uses the tokens generated by the lexical analyser to check if the infix expression is syntactically valid. It does this by following a set of rules:

Rule 1: An expression must contain at least 2 numbers and 1 operator.

Rule 2: An operator token can never occur at the start or at the end of the expression.

Rule 3: The number of open parentheses must be equal to the number of close parentheses.

Rule 4: There can never be adjacent operator tokens or number tokens.

Rule 5: An open parenthesis token can never be immediately followed by a close parenthesis token or vice-versa.

Rule 6: An open parenthesis token can never be immediately followed by an operator token, nor can an operator token be immediately followed by a close parenthesis token.

Rule 7: Going from left to right in the expression, the number of close parentheses can at no point be greater than the number of open parentheses.

The 7 rules listed above are written in a function called **isInfValid** (which stands for “Is infix valid?"). It receives the list of token labels generated by the lexer, and based on the position and sequence of the token labels, evaluates whether the infix expression is syntactically valid. It returns ‘True’ if the expression is valid, and ‘False’ if not.

A great advantage of postfix expressions is that they do not contain any parentheses and there are no operator precedence rules to consider. However, this is because parentheses and operator precedence rules are taken care of by the shunting-yard algorithm. Operator precedence rules are defined in the parser module in the **precedence** function, and the shunting-yard algorithm (in the **shuntingYard** function) invokes this function to decide the order in which to rearrange tokens in the postfix format.

### The Evaluator

Once the tokens in postfix have been generated, calculating the expression is fairly straightforward. The evaluation is handled by the **evalRPN** function in the ‘calcEval’ module, which receives from the parser the list of tokens in postfix format.
